{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neftune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路：输入经过Embedding层后，再加入一个均匀分布的噪声"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./forum.png\" width=\"600\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 19,  1, 17, 19],\n",
       "        [ 4, 11, 10,  9, 13]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "my_embedding=torch.nn.Embedding(num_embeddings=20, embedding_dim=100)\n",
    "\n",
    "random_input=torch.randint(0,20,(2,5))\n",
    "\n",
    "random_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_embedding_output=my_embedding(random_input)\n",
    "\n",
    "origin_embedding_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neftune_post_forward_hook(module, input, output):\n",
    "    dims = torch.tensor(output.size(1) * output.size(2))\n",
    "    mag_norm = module.neftune_noise_alpha / torch.sqrt(dims)\n",
    "    output = output + torch.zeros_like(output).uniform_(-mag_norm, mag_norm)\n",
    "    return output\n",
    "\n",
    "my_embedding.neftune_noise_alpha = 0.2\n",
    "\n",
    "handle_neftune=my_embedding.register_forward_hook(hook=neftune_post_forward_hook)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neftune_embedding_output=my_embedding(random_input)\n",
    "neftune_embedding_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(origin_embedding_output, neftune_embedding_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0089)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2/torch.sqrt(torch.tensor(5.0*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0089, grad_fn=<MaxBackward1>),\n",
       " tensor(-0.0089, grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_noise=neftune_embedding_output-origin_embedding_output\n",
    "torch.max(test_noise),torch.min(test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_neftune.remove()\n",
    "del handle_neftune#删除钩子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neftune_remove_embedding_output=my_embedding(random_input)\n",
    "neftune_remove_embedding_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(origin_embedding_output, neftune_remove_embedding_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 获取维度 dims = torch.tensor(output.size(1) * output.size(2))  \n",
    "2. 获取norm mag_norm = module.neftune_noise_alpha / torch.sqrt(dims)\n",
    "3. 获取噪声 torch.zeros_like(output).uniform_(-mag_norm, mag_norm)\n",
    "4. 将噪声加到输出上 output = output + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers/src/transformers/trainer_utils.py\n",
    "def neftune_post_forward_hook(module, input, output):\n",
    "    \"\"\"\n",
    "    Implements the NEFTune forward pass for the model using forward hooks. Note this works only for torch.nn.Embedding\n",
    "    layers. This method is slightly adapted from the original source code that can be found here:\n",
    "    https://github.com/neelsjain/NEFTune Simply add it to your model as follows:\n",
    "    ```python\n",
    "    model = ...\n",
    "    model.embed_tokens.neftune_noise_alpha = 0.1\n",
    "    model.embed_tokens.register_forward_hook(neftune_post_forward_hook)\n",
    "    ```\n",
    "    Args:\n",
    "        module (`torch.nn.Module`):\n",
    "            The embedding module where the hook is attached. Note that you need to set `module.neftune_noise_alpha` to\n",
    "            the desired noise alpha value.\n",
    "        input (`torch.Tensor`):\n",
    "            The input tensor to the model.\n",
    "        output (`torch.Tensor`):\n",
    "            The output tensor of the model (i.e. the embeddings).\n",
    "    \"\"\"\n",
    "    if module.training:\n",
    "        dims = torch.tensor(output.size(1) * output.size(2))\n",
    "        mag_norm = module.neftune_noise_alpha / torch.sqrt(dims)\n",
    "        output = output + torch.zeros_like(output).uniform_(-mag_norm, mag_norm)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激活neftune\n",
    "1. 判断类型取出embeddings  \n",
    "2. hook_handle=embeddings.register_forward_hook(neftune_post_forward_hook)在embedding的前向传播中注册hook  \n",
    "3. self.neftune_hook_handle = hook_handle保存hook  \n",
    "\n",
    "取消neftune\n",
    "1. 判断类型取出embeddings\n",
    "2. self.neftune_hook_handle.remove() 移除hook\n",
    "3. del embeddings.neftune_noise_alpha, unwrapped_model 移除alpha属性\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers/src/transformers/trainer.py\n",
    "def _activate_neftune(self, model):\n",
    "        r\"\"\"\n",
    "        Activates the neftune as presented in this code: https://github.com/neelsjain/NEFTune and paper:\n",
    "        https://arxiv.org/abs/2310.05914\n",
    "        \"\"\"\n",
    "        unwrapped_model = self.accelerator.unwrap_model(model)\n",
    "\n",
    "        if _is_peft_model(unwrapped_model):\n",
    "            embeddings = unwrapped_model.base_model.model.get_input_embeddings()\n",
    "        else:\n",
    "            embeddings = unwrapped_model.get_input_embeddings()\n",
    "\n",
    "        del unwrapped_model\n",
    "\n",
    "        embeddings.neftune_noise_alpha = self.neftune_noise_alpha\n",
    "        hook_handle = embeddings.register_forward_hook(neftune_post_forward_hook)\n",
    "        self.neftune_hook_handle = hook_handle\n",
    "        return model\n",
    "\n",
    "    def _deactivate_neftune(self, model):\n",
    "        \"\"\"\n",
    "        Deactivates the neftune method. Make sure to call `_activate_neftune` first.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"neftune_hook_handle\"):\n",
    "            raise ValueError(\"Neftune is not activated make sure to call `trainer._activate_neftune()` first\")\n",
    "\n",
    "        unwrapped_model = self.accelerator.unwrap_model(model)\n",
    "\n",
    "        if _is_peft_model(unwrapped_model):\n",
    "            embeddings = unwrapped_model.base_model.model.get_input_embeddings()\n",
    "        else:\n",
    "            embeddings = unwrapped_model.get_input_embeddings()\n",
    "\n",
    "        self.neftune_hook_handle.remove()\n",
    "        del embeddings.neftune_noise_alpha, unwrapped_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
